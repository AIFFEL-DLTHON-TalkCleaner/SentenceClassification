{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXfWf6ugxZO0",
    "outputId": "7efde34e-2e22-4dd2-d7a6-52f061c3f8cc"
   },
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5o1IiQlyy4Vu",
    "outputId": "0eca8bd6-edce-4095-f979-a9f247c2d5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/dktc\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhX9uhJ30iVc",
    "outputId": "8da7d599-fbfb-42e4-8c13-8aa07dce19df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wvdYrDsgexp6"
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "eBsci5ZXepQp",
    "outputId": "54abfb1f-3a21-4a59-c529-d9c65bd0550b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function transformers.utils.logging.set_verbosity_info()>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_Y7-jBNi02j5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "                            roc_auc_score, confusion_matrix, classification_report, \\\n",
    "                            matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()  #GPU가 torch 캐치 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)  #지금 잡은 device뭔지 보여줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tB81TBCsTgXz",
    "outputId": "b1c1b67f-0dcd-45cb-fd86-44e7bab954dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmQ-1HSSmCaq",
    "outputId": "d3d80553-9ce5-4bf9-e047-eabf713e6ba9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForSequenceClassification)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer), type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6RtSymb0-rg"
   },
   "source": [
    "**언어모델 및 Tokenizer 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jf1OMGjS2Y5n"
   },
   "source": [
    "**데이터셋 가져오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hx1yP3jUzswl",
    "outputId": "5050a325-85fc-4b28-9552-ceafa76a40b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>휴일이니...쉬게해주세요내말이 ... ㅜㅜ 너무 가기 싫어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>물고기 잡아 올리는 것도 할 수 있어?하하 응 그게 묘미더라 물고기 잡혔을 때 ㅎ/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 이새끼 봐바 오타쿠인가봐\\n 뭔데뭔데 아 뭐냐 그림. 이게 그 미미쨩인가 그거냐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그랬는데, 내가 몰래 여사친 만나다가 여자친구한테 걸려서... 여자친구가 울면서 헤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야.근데.이렇게 하는거 맞아.???\\n맞다고 병신아!!\\n야 근데 왜 자꾸 욕해.?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      class                                       conversation\n",
       "0           0      일반 대화                   휴일이니...쉬게해주세요내말이 ... ㅜㅜ 너무 가기 싫어\n",
       "1           1      일반 대화  물고기 잡아 올리는 것도 할 수 있어?하하 응 그게 묘미더라 물고기 잡혔을 때 ㅎ/...\n",
       "2           2  기타 괴롭힘 대화  야 이새끼 봐바 오타쿠인가봐\\n 뭔데뭔데 아 뭐냐 그림. 이게 그 미미쨩인가 그거냐...\n",
       "3           3      일반 대화  그랬는데, 내가 몰래 여사친 만나다가 여자친구한테 걸려서... 여자친구가 울면서 헤...\n",
       "4           4  기타 괴롭힘 대화  야.근데.이렇게 하는거 맞아.???\\n맞다고 병신아!!\\n야 근데 왜 자꾸 욕해.?..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"merged_df_4000.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9NL4Ex9H0SYy"
   },
   "outputs": [],
   "source": [
    "# class 대화 라벨링하기\n",
    "\n",
    "data['class'].unique()\n",
    "class_labels = {\"협박 대화\":0, \"기타 괴롭힘 대화\":1, \"갈취 대화\": 2, \"직장 내 괴롭힘 대화\":3, \"일반 대화\": 4}\n",
    "data['label'] = data['class'].map(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Y3J_QUwD2wC2",
    "outputId": "1530a5e7-af52-4987-aab9-84690dd85566"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>휴일이니...쉬게해주세요내말이 ... ㅜㅜ 너무 가기 싫어</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>물고기 잡아 올리는 것도 할 수 있어?하하 응 그게 묘미더라 물고기 잡혔을 때 ㅎ/...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 이새끼 봐바 오타쿠인가봐\\n 뭔데뭔데 아 뭐냐 그림. 이게 그 미미쨩인가 그거냐...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>그랬는데, 내가 몰래 여사친 만나다가 여자친구한테 걸려서... 여자친구가 울면서 헤...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야.근데.이렇게 하는거 맞아.???\\n맞다고 병신아!!\\n야 근데 왜 자꾸 욕해.?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      class                                       conversation  \\\n",
       "0           0      일반 대화                   휴일이니...쉬게해주세요내말이 ... ㅜㅜ 너무 가기 싫어   \n",
       "1           1      일반 대화  물고기 잡아 올리는 것도 할 수 있어?하하 응 그게 묘미더라 물고기 잡혔을 때 ㅎ/...   \n",
       "2           2  기타 괴롭힘 대화  야 이새끼 봐바 오타쿠인가봐\\n 뭔데뭔데 아 뭐냐 그림. 이게 그 미미쨩인가 그거냐...   \n",
       "3           3      일반 대화  그랬는데, 내가 몰래 여사친 만나다가 여자친구한테 걸려서... 여자친구가 울면서 헤...   \n",
       "4           4  기타 괴롭힘 대화  야.근데.이렇게 하는거 맞아.???\\n맞다고 병신아!!\\n야 근데 왜 자꾸 욕해.?...   \n",
       "\n",
       "   label  \n",
       "0      4  \n",
       "1      4  \n",
       "2      1  \n",
       "3      4  \n",
       "4      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1HiNS43vuS"
   },
   "source": [
    "여기서 작은 모델만 training 하는 거니까 len 작게만...0.1만 뽑겠당."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHNtwAFE3rh4",
    "outputId": "43bbbf11-713f-47aa-f6e7-7a05295d9edd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7950"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NacyePLq36tY"
   },
   "outputs": [],
   "source": [
    "sampled_data = data.sample(frac=0.05, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6N641jVE4Qr3",
    "outputId": "bb1d7058-fd92-4aa4-cd37-0707dbd8d434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    196\n",
       "0     57\n",
       "1     52\n",
       "2     51\n",
       "3     42\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koDvs4kA_JSu",
    "outputId": "45513c95-8471-4004-aba2-074e0a6428d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 398 entries, 3832 to 2389\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    398 non-null    int64 \n",
      " 1   class         398 non-null    object\n",
      " 2   conversation  398 non-null    object\n",
      " 3   label         398 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 15.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#결측치 확인\n",
    "sampled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DxZzx70K_RqQ",
    "outputId": "fb02232b-031b-405b-eb97-ef9617d8b524"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, class, conversation, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#중복값 확인\n",
    "sampled_data[sampled_data['conversation'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KrRoqu1u_hJ7"
   },
   "outputs": [],
   "source": [
    "#중복값 제거\n",
    "#sampled_data.drop_duplicates(subset = ['conversation'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2oVqd9Zu-jHT"
   },
   "outputs": [],
   "source": [
    "# def remove_null_conversations(dataframe):\n",
    "#     # 'conversation_split' 열의 null 값 찾기\n",
    "#     null_conversations = dataframe[dataframe['conversation_split'].isnull()]\n",
    "\n",
    "#     # null 값이 있는지 확인하고, 있다면 해당 행 제거\n",
    "#     if not null_conversations.empty:\n",
    "#         dataframe = dataframe.dropna(subset=['conversation_split'])\n",
    "\n",
    "#     return dataframe\n",
    "\n",
    "# 함수 호출\n",
    "cleaned_data = sampled_data\n",
    "\n",
    "# # 결과 확인\n",
    "# cleaned_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOuIOpwPDxKi"
   },
   "source": [
    "## BERT 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TtKASRfB-92o"
   },
   "outputs": [],
   "source": [
    "X_data = cleaned_data['conversation']\n",
    "y_data = cleaned_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Iv3OSmsREFXB"
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2 # Train: Test = 8 :2 분리\n",
    "RANDOM_STATE = 2024\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,\n",
    "                                                    test_size = TEST_SIZE,\n",
    "                                                    random_state = RANDOM_STATE,\n",
    "                                                    stratify = y_data)  #stratify하면 데이터 분리 이전의 라벨별 비율을 고려해 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aiXH68wqhOnb",
    "outputId": "27a18de0-d061-443a-a0ca-28f97f10ae5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645    야 너 눈 안보이냐?\\n응 나 앞이 안보여\\n장님이네 야 따라와봐\\n눈이 안보여서 ...\n",
       "2573                      가을 즐기기엔 너무 짧았지.다음주엔 외출을 좀 해야겠어.\n",
       "4570    ? 예상이 가지? 대화를 하러 왔어.\\n 눈을 가리고 의자에 묶어둔 채로?\\n 거절...\n",
       "6932                           샤오미도 품질 좋아?좋다기보단 가성비 좋은편이야\n",
       "4486    씨는 좋겠다?\\n네?\\n애인도 있고 집도 있고 차도 있고. 히야 부러워\\n아닙니다....\n",
       "                              ...                        \n",
       "5515    네 여보세요? 최세정씨 맞으시죠\\n네 맞는데 무슨일이죠?\\n다름이 아니라 공중 화장...\n",
       "1376    지금 또 청소기 돌렸어요? 다들 퇴근후 쉬어야하는 시간인데 너무 시끄럽네요\\n 아니...\n",
       "742                  축구할 때 포지션이 어디야?나는 다 뛰는데 미드필드를 제일 좋아해\n",
       "1128           오호 ㅋㅋ 정보 ㄳㄳ 그래야겠다 ㅋㅋㅋㅋ 지성이면 수분크림 많이 발라줘야겠다\n",
       "2087    그러니까 시키는 일만 했어야지\\n어디를 더 부러뜨려 줄까\\n시키는대로 했잖아!\\n그...\n",
       "Name: conversation, Length: 318, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rnnFAn9vXMws"
   },
   "outputs": [],
   "source": [
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()\n",
    "y_train_list = y_train.tolist()\n",
    "y_test_list = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMkSL9_wXN-C",
    "outputId": "3b708a1d-8ce6-4899-eae3-50795c8d5a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "q83jA1pWX851"
   },
   "outputs": [],
   "source": [
    "dic = {0: \"협박 대화\", 1:\"기타 괴롭힘 대화\", 2:\"갈취 대화\", 3:\"직장 내 괴롭힘 대화\", 4:\"일반 대화\"}\n",
    "ans_train = torch.tensor(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7tLZ3OfvkIiA"
   },
   "outputs": [],
   "source": [
    "def create_batches(input_list, output_list, batch_size):\n",
    "  assert len(input_list) == len(output_list)\n",
    "  for i in range(0, len(input_list), batch_size):\n",
    "        yield (input_list[i:i + batch_size], output_list[i:i + batch_size])\n",
    "\n",
    "BATCH_SIZE = 8  # You can adjust this as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "id": "-zVJ_RWpBMZh",
    "outputId": "f9aa3cbc-2ba4-4899-b63e-3be732e2e503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:5.661579132080078\n",
      "epoch:1, loss:23.87445831298828\n",
      "epoch:1, loss:20.362987518310547\n",
      "epoch:1, loss:66.4600830078125\n",
      "epoch:1, loss:86.92110443115234\n",
      "epoch:1, loss:27.869606018066406\n",
      "epoch:1, loss:14.180756568908691\n",
      "epoch:1, loss:7.319157123565674\n",
      "epoch:1, loss:20.188993453979492\n",
      "epoch:1, loss:25.542627334594727\n",
      "epoch:1, loss:10.18469524383545\n",
      "epoch:1, loss:21.663721084594727\n",
      "epoch:1, loss:12.672140121459961\n",
      "epoch:1, loss:16.545392990112305\n",
      "epoch:1, loss:68.350341796875\n",
      "epoch:1, loss:21.380517959594727\n",
      "epoch:1, loss:13.71363353729248\n",
      "epoch:1, loss:9.785932540893555\n",
      "epoch:1, loss:29.871612548828125\n",
      "epoch:1, loss:29.66653060913086\n",
      "epoch:1, loss:19.735458374023438\n",
      "epoch:1, loss:4.408719539642334\n",
      "epoch:1, loss:14.945531845092773\n",
      "epoch:1, loss:14.425537109375\n",
      "epoch:1, loss:40.574920654296875\n",
      "epoch:1, loss:11.316981315612793\n",
      "epoch:1, loss:8.54213809967041\n",
      "epoch:1, loss:17.299060821533203\n",
      "epoch:1, loss:10.84618091583252\n",
      "epoch:1, loss:56.50577926635742\n",
      "epoch:1, loss:15.992843627929688\n",
      "epoch:1, loss:0.0003660168149508536\n",
      "epoch:1, loss:28.381431579589844\n",
      "epoch:1, loss:35.245548248291016\n",
      "epoch:1, loss:19.75816535949707\n",
      "epoch:1, loss:26.70827865600586\n",
      "epoch:1, loss:22.528718948364258\n",
      "epoch:1, loss:9.64188289642334\n",
      "epoch:1, loss:10.057896614074707\n",
      "epoch:1, loss:14.977619171142578\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185/3245955527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# 에폭당 평균 손실 계산 및 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mavg_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch:{epoch+1}, average loss:{avg_epoch_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch_losses' is not defined"
     ]
    }
   ],
   "source": [
    "# 런타임 1분 소요\n",
    "# 활성화 함수 AdamW 불러오기\n",
    "from transformers import AdamW\n",
    "\n",
    "# 활성화 함수 AdamW 인스턴스화\n",
    "optimizer = AdamW(model.parameters(), lr=0.05)\n",
    "\n",
    "# 모델을 학습 모드로 변경\n",
    "model.train()\n",
    "\n",
    "# 에포크 수 지정 및 손실을 담은 빈 컨테이너 리스트 생성\n",
    "epochs =1\n",
    "losses = []\n",
    "\n",
    "# 파인튜닝\n",
    "for epoch in range(epochs):\n",
    "    for batch, labels in create_batches(X_train_list, ans_train, BATCH_SIZE):\n",
    "        inputs = tokenizer.batch_encode_plus(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 그래디언트(기울기) 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 변수 eval_list에 담긴 여섯 개 문장을 토크나이저에 넣고 인코딩\n",
    "        #inputs = tokenizer.batch_encode_plus(X_train_list, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        # 위에서 생성된 input 변수에 담긴 키(key)와 키값(value)을 **inputs 형식(**kwargs 형식)으로 모델에 전달\n",
    "        # 거기에 추가로 labels를 텐서 타입으로 모델에 전달\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        # 로짓 추출\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # 손실 추출\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # 오차역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 가중치(weight) 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실을 빈 컨테이너 losses에 순서대로 저장\n",
    "        losses.append(loss)\n",
    "\n",
    "        # 에포크 및 손실 값 출력\n",
    "        # 에포크는 0부터 시작하기에, 1을 더해줘서 사람들이 에포크 회수를 더 자연스럽게 인지하게 조치\n",
    "        print(f\"epoch:{epoch+1}, loss:{loss}\")\n",
    "\n",
    "    # 에폭당 평균 손실 계산 및 출력\n",
    "    avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f\"epoch:{epoch+1}, average loss:{avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vIPo05fuaDqV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_losses = [i.item() for i in losses]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(new_losses);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "WRmV8uJPbclC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일반 대화:요즈음 다 저걸로 홍보하더라나도 당장 사야겠다/나 맨날 지저분하게 지워져서 스트레스였어\n",
      "일반 대화:야 야 내가 좀 춥다 환절기 되니까 좀 쌀쌀해 그렇지?\n",
      "어어? 그러네\n",
      "와 이새끼 패딩 좋은거 입고 다니네\n",
      "아 고마워\n",
      "아니 고마워말고 좀 벗어봐\n",
      "응?\n",
      "나도 한번 입어보자\n",
      "어? 입어만 보는거지?\n",
      "응 입어보니까 보는 것만으로도 다르네 야 이거 내가 지금 추우니까 입고 다음주에 돌려줄게\n",
      "어?안되는데\n",
      "야 그럼 내가 추워 얼어 죽었으면 좋겠냐??\n",
      ".아니. 그건아닌데\n",
      "그럼 주말 잘보내라 나 간다\n",
      "일반 대화:오 신발샀냐?\n",
      "응. 전에 신던게 다 헤져서.부모님이 사주셨어.\n",
      "니네 집 꽤 사나보다? 이런 신발도 잘 사주시고?\n",
      "응.? 그런건 아닌데.그래도 신발은 오래 신는 거라고.\n",
      "잠깐 벗어봐. 나 한 번만 신어보자.\n",
      "어.돌려줄거지.?\n",
      "아 장난치냐 내가 그럼 니가 신 던거 가져갈까봐 그래? 빨리 내놔보라고.\n",
      "잠깐만이야.\n",
      "와 이거 딱 내 신발이네. 야 나 이거 몇일만 빌려주라 내가 신으니까 니가 신을 때보다 더 간지나잖아. 고맙다 잘 신을게\n",
      "돌려줘.! 정말 안돼.저번에도 너가 빌려갔다가.다 헤져서 산 거란 말이야.\n",
      "일반 대화:나는 아몬드 봉봉 제일 좋아해아몬드 봉봉도 인기 좋지 ㅋㅋ/난 후식은 상큼한 게 좋더라구\n",
      "일반 대화:아니 나한테 송아지를 넘기기로 했으면서 이제와서 무슨말인가\n",
      "아 저기 옆마을 한씨가 더 비싸게 쳐주기로한다지 뭔가\n",
      "아니 그래도 사람이 약속한 게 있지!\n",
      "약속은먼저 했는데 나도 돈이 궁해서 그랬네 미안하네\n",
      "미안하다고 하면 단가?\n",
      "그럼 어쩌라고? 내가 뭐 무릎이라고 꿇고 빌어야하나?\n",
      "하. 진짜 적반하장이고만 내가 이대로 물러날것같은가?\n",
      "안그러면 어쩌려고?\n",
      "그 송아지 못팔게 내가 지금 낫으로 막 찔러 죽여블거구만\n",
      "뭣이야? 나도 가만 있을지 알고? 나도 자네집 소들 다 죽여블거구만\n",
      "일반 대화:넌 어디 아픈데 없어?난 요즘 시력이 안좋아져서 걱정이야ㅠㅠ/안과 추천 좀 해줘\n",
      "일반 대화:물고기 잡아 올리는 것도 할 수 있어?하하 응 그게 묘미더라 물고기 잡혔을 때 ㅎ/매력 있어\n",
      "일반 대화:다음 주 데이트 코스 짜자!나는 일단 쉬고 싶어!\n",
      "일반 대화:당신이 우리 딸에게 이 약 먹으면 살 빠진다고 했다면서?\n",
      " 따님은 체중감량할 필요없어서 다이어트 약 처방을 거부했습니다. 그런데 막무가내로 원하셔서 처방했습니다.\n",
      " 그게 그거 아니야? 당신떄문에 우리 딸이 죽었어!\n",
      " 그게 왜 저 때문인가요? 따님은 제가 처방한 약 이외에도 너무 많은 약들을 먹었어요.\n",
      " 당신이 의사야? 이 살인자. 당신 내가 가만안둘거야 죽여버리겠어! 우리딸처럼 당신도 한번 죽어봐\n",
      " 무슨소리입니까 오남용한 당신 딸 때문이지. 어서 나가세요!\n",
      " 이 병원 내가 다 소문내고 당신 얼굴 못 들고 다닐게 할거야! 어디 한번 너도 당해봐.\n",
      " 이러면 나도 가만히 안했습니다. 어디 해 볼테면 해보세요!\n",
      " 좋아. 한번 해보시겠다?\n",
      " 당신같이 남의 탓하면서 비난하는 사람들 여럿봤습니다. 저도 생각이 있어요!\n",
      "일반 대화:야!.야!야야!!\n",
      "네?\n",
      "너 몇학년이야?\n",
      "1학년이요.\n",
      "1학년? 선배가 부르는데 대답을 똑바로 안해?\n",
      "무슨 일때문에 그러세요.\n",
      "아 내가 갑자기 출출해져서 밥좀 사먹어야하는데 돈이 없네?\n",
      "아. 제가 돈이 없는데.\n",
      "그래?\n",
      "네. 돈이 없어요.\n",
      "그럼 찾아서 나오면 10원에 한대씩이다?\n",
      "일반 대화:그런데 그런 것 말고 신체적으로 문제가 경우 상하차가 불가피한데 불법이라서 논란이 되고 있더라고그런 일도 있을 수 있다는 걸 간과한 모양이네\n",
      "일반 대화:친구야. 나 할 말이 있어.\n",
      "오랜만에 봤는데 왜 이리 진지모드냐? 고민있어? \n",
      "응.\n",
      "야이 자식아 친구 좋은 게 뭐냐. 얼른 불어. 보증 빼곤 다 도와줄라니까.\n",
      "장난 치는 거 아니야. 나. 니가 소중해서 말하는거야.\n",
      "뭔데?\n",
      "봤어. 그 날. 바다에서 걔 니가 죽였지.? 자수해\n",
      "너 자신있어? \n",
      "응? 그게 무슨.\n",
      "너희 부모님 속초에 계시지? 접때 같이 갔을 때 물 좋고 산 좋던데. 부모님 다시 뵙기 싫으면. 부탁한다. 친구야.\n",
      "일반 대화:야 돈좀있냐?\n",
      "아니 없는데\n",
      "아니 없는데? 없는데? 말이짧다?\n",
      "아니요 없어요\n",
      "야 있는거 다 까봐\n",
      "이게 전부에요\n",
      "야 여기 이건 뭐냐? 확씨 너 구라치면 뒤진다\n",
      "정말 이게 다에요.\n",
      "뭐 이런 그지새끼가 다있어\n",
      "죄송합니다. 이제 보내주세요.\n",
      "일반 대화:너 돈있어?\n",
      "아니요 \n",
      "내가찾아볼까?\n",
      "싫어요 \n",
      "나 참.\n",
      "왜 남의 가방을 뒤지세요 \n",
      "아무말 하지마\n",
      "헉 \n",
      "가방에 돈있네\n",
      "빌린돈 갚아야해요.\n",
      "일반 대화:좋아 ㅋㅋ 나는 심플로 마음이 기울었긴 해흠... 근데 청첩장엔 돈 많이 쓰지 말라곤 하더라 ㅠㅠ\n",
      "일반 대화:나도 아직은 바다가 좋은데 등산도 재밌을 것 같아등산은 많이 힘들지 않을까?\n",
      "일반 대화:정세운씨 ㅋㅋ 동생한테 말할까? 만나볼래?당연하지 나 내일 옷 사러 간다^^/당연하지 나 내일 옷 사러 간다^^\n",
      "일반 대화:엄마 나 돈줘 돈주라고\n",
      " 엄마가 이것밖에 없어\n",
      "우리집은 왜이렇게 지지리 궁상이야?\n",
      "미안하네 딸\n",
      "미안하면 돈이나 더주던가 친구들은 더 좋은거 신고다닌단말야 나만 이런거 들고 다녀\n",
      "미안해 엄마가 다음달에 어떻게든 하나 사줘볼게\n",
      "또 거지같은거 사주지말고 이건 뭐야? 돈 더있었잖아!!\n",
      "그거는 오늘 월세야\n",
      "나 이거 줘\n",
      "안돼 지혜야 이거로 우리 방세 내야지\n",
      "아 몰라몰라 나 들고 나갈거야 왜 이런 집구석에 나를 태어나게해서 엄마는 죄인이야!\n",
      "지혜야 안돼!!\n",
      "일반 대화:야 너 돈 많이 있어 보이네 \n",
      "네 저 많이 없어요 왜 그러세요\n",
      "시끄러 옷차림 보니 고급진게 돈많아 보이네\n",
      "아니 없다니깐요\n",
      "잔말 말고 내놔\n",
      "살려주세요\n",
      "뭐야 이놈 진짜로 없네 거지 아니야 완전\n",
      "제가 말했잖아요 저 이제 가도 되죠\n",
      "아니 안돼 니 옷이라도 벗어 죽기 싫으면\n",
      "아니 진짜\n",
      "일반 대화:오른팔을 자를까 왼팔을 자를까\n",
      "잘못했습니다. 살려주세요\n",
      "니가 훔쳐간 물건만 돌려놓으면 돼\n",
      "저도 당한겁니다. 물건을 주면 돈을 준다고 했는데 물건만 다 빼앗겨버렸어요.\n",
      "그럼 니 왼팔 오른 팔도 다 빼앗기는거지.\n",
      "조금만 시간을 주시면 제가 다시 되찾아 오겠습니다.\n",
      "3일안에 찾아와\n",
      "3일은 너무 짧습니다.시간을 조금만 더 주시면.\n",
      "2일\n",
      ".3일안에 찾아오겠습니다.\n",
      "일반 대화:둘째도 또 딸이니?\n",
      "아 .네 .\n",
      "첫째도 딸 둘째도 딸 .너 무슨 애가\n",
      "아.\n",
      "딸 낳는 기계니?\n",
      "죄송합니다 .\n",
      "죄송하면 아들 좀 낳아 ! 딸 좀 그만 낳고\n",
      ".노력해볼께요\n",
      "아휴 말만 노력한다 뭐한다 그래놓고 아들은 무슨 딸만 주구장창 낳기만하고 아휴 \n",
      "어머님 .\n",
      "계속 딸만 낳을거면 이 집에서 당장 나가\n",
      "일반 대화:니꺼 가방 좋아보이는데 나주라\n",
      "안되\n",
      "그럼 며칠만 빌려줘봐\n",
      "싫다고 나도 아끼는거야\n",
      "내꺼랑 교환해서 쓰자 그럼\n",
      "마음에 들면 니가 사서 써\n",
      "돈이 없어서 그렇지\n",
      "있는거나 써야지\n",
      "안준다는거냐?\n",
      "응 안될꺼같아\n",
      "내말도 안듣고 각오해라\n",
      "일반 대화:너는 어느 계절을 제일 극혐해?여름 난 더운 건 질색이야!\n",
      "일반 대화:뭐야.? 너가 왜 우리집에 있는거야?\n",
      " 그러니까 만나달라고 좋게 말할 때 만나줬으면 좋았잖아.\n",
      " 우리 헤어졌잖아. 헤어졌는데 뭘 다시 만나? 그건 그렇고 우리집은 어떻게 들어온거냐고!!!\n",
      " 난 못 헤어져. 내가 왜 헤어져.? 나 너 없인 안돼. 누구 좋으라고 헤어져?\n",
      " 당장 나가!!!!!!!!!! 경찰 부를거야 당장 나가!!!!!!!!\n",
      " 우리가 함께 할 수 없으면 같이 죽자 그냥\n",
      " 미.친거지.? 그 칼 뭐야.?\n",
      " 너가 자초한 일이야. 난 이제 잃을 것도 없어. 무서운 것도 없다고. 세상에서 제일 무서운게 잃을 거 없는 사람인 거 알지 \n",
      " 겨.경찰.\n",
      " 내가 하게 냅둘 거 같아?\n",
      " 오열하며 무릎꿇고 .사.살려줘. 이러지마 이.이.러면. 너도 .무사하지 못해.\n",
      " 상관없어. 그냥 같이 죽자. 같이 죽고 지옥에서 함께하자.\n",
      " 무릎꿇고 싹싹 빌며 하.하라는대로.할게.제발.\n",
      " 처음부터 이랬으면 좋았잖아 우리가 어떻게 헤어져. 못헤어져. 영원히 함께야 우리는.\n",
      "일반 대화:교환학생 알아보고 있는데 장점이 뭘까?음 어학공부를 좀 더 깊게 할 수 있다는 거\n",
      "일반 대화:살면 사먹으려나응응 첨엔 해먹다가 결국 이길로 들어설 것이다\n",
      "일반 대화:환절기라 컨디션이 안 좋아서 그런가?글쎄, 잘 모르겠는걸?\n",
      "일반 대화:이거 니가 계산해!\n",
      "어? 알았어\n",
      "적립은 제껄로 해주세요 !\n",
      "야 내가 계산하는데 왜 니꺼로 적립해?\n",
      "왜 내 맘이지? \n",
      "아 진짜 너 너무 한거아니니?\n",
      "너 식충이야? 매일 얻어먹었잖아 돈없냐? \n",
      "내가 언제 맨날 얻어먹었어 맨날 사주기만 했지\n",
      "야 이제 좀 눈치껏 너도 계산 좀 해 너가 그러니까 친구가 다 떠나는거야\n",
      "작작 좀 해라\n",
      "일반 대화:김주임 일 처리 똑바로 안할거야?\n",
      "죄송합니다 부장님.\n",
      "자네 동기들은 다 벌써 대리고 과장이고 달았는데 왜 자네만 아직 주임인지 알겠구만. 이렇게 덜떨어져가지고.\n",
      "죄송합니다 앞으로 더 신경쓰겠습니다.\n",
      "죄송하면 다야? 이게 대체 몇번째야? 자네 머리가 좀 모자란거 아닌가? 학력 좋대서 뽑았더니 이거 원.\n",
      "죄송합니다.\n",
      "자네 회사가 만만해? 놀러 오나? 자네를 쓰느니 차라리 저기 놀이터에서 노는 애를 데려다 쓰는게 낫겠어 아주.\n",
      "죄송합니다 시정하겠습니다.\n",
      "대가리가 있으면 생각을 좀 해 알았어? 한번 더 이딴식으로 하면 회사고 뭐고 다 때려쳐.\n",
      "일반 대화:야 머하냐?\n",
      "아 깜짝이야. 인기척 좀 하지. 놀랐잖아.\n",
      "야 멀 놀라 그게 놀랄일이냐\n",
      "난 놀란다고. 그리고 때리지마.\n",
      "야 멀 때려 그냥 부른거지\n",
      "넌 그래도 난 아파.\n",
      "힘 들어가지도 않았거든 뭘 아파 너 울보지?\n",
      "아니야 나 울보아니야.\n",
      "멀 아니야 지금 말하는데도 울려고 하는데\n",
      "승민이는 울보래요 울보래요\n",
      "일반 대화:돈 이리 내\n",
      "이거 학원비야 안돼\n",
      "잠깐만 쓰고 돌려준다고\n",
      "시 싫어\n",
      "싫어? 맞을래?\n",
      "엄마한테 혼나 학원비란 말야\n",
      "빨리 내놔 맞기 싫으면\n",
      "으 으윽 안돼\n",
      "우리 친구잖아 친구끼리 돈 빌려주는 거잖아\n",
      "제발. 제발 봐줘\n",
      "어서 내놔\n",
      "일반 대화:서서 일하는 거야? 다리 아프겠다 ㅠㅠ 그만 둘 생각은 없어? 너무 힘들어 보여 ㅠㅠ아냐 그래도 일 자체는 별로 안 힘들어 심지어 엄청 재밌어! 하하\n",
      "일반 대화:몰라 그런 것 같아 무서웠음 ㅠㅋㅋ 요즘 광안리 가면 산책 엄청 시키잖아 ㅠ/망망이 귀여운뎅,\n",
      "일반 대화:친구야 내가 정말 급해서 그러는 데 돈 좀 빌려주면 안될까?\n",
      "저번에도 빌려가고 안값았잖아. 안돼.\n",
      "이씨 누가 안값는데? 어차피 빌려준 거 조금 더 빌려줄 수 있잖아?\n",
      "싫어. 빌려간 돈이 한두푼도 아니고 한 번도 값은 적 없잖아\n",
      "아 이렇게 나오시겠다? 그럼 이 사진 학과커뮤니티에 올려도 된다는 거지?\n",
      "그 사진은 어떻게!! 안돼!! 그러지마\n",
      "그러니까 돈 좀 빌려달라고 친구야.\n",
      "신. 신고할거야\n",
      "이미 사진은 다 퍼진 후일걸?\n",
      ". 이게 전부야. 이만큼밖에 못 빌려줘.\n",
      "어차피 빌려줄거면서 고맙다 친구야?\n",
      ".값을거지?\n",
      "그럼그럼\n",
      "일반 대화:맞아 나는 트리트먼트 매일 하는데 왜그럴까?그거 트리트먼트 모발 끝쪽에만 바르고 잠시 방치해둬야한대\n",
      "일반 대화:그럼 지금 나와 먹으러 가자 ㅋㅋㅋㅋ 홈플러스몰 장바구니 담어/ㅋㅋ 내가 결제할게~\n",
      "일반 대화:뭘 꼬라봐?\n",
      " 왜 시비세요?\n",
      " 끝까지 꼬라보네? 눈깔 뽑히고 싶냐?\n",
      " 아니 한번 쳐다봤다고.\n",
      " 니 어디 사냐? 오늘 니 집 좀 알아야겠다\n",
      " 왜 그러세요. 경찰 부르기 전에 그만하세요\n",
      " 불러봐! 부르는 순간 넌 나한테 죽는거야\n",
      " 그만하고 가주세요. 죄송합니다\n",
      " 새끼가 까불고 있어. 뒤지기 싫으면 눈 잘 깔고 다녀라\n",
      " 예. 죄송합니다\n",
      "일반 대화:그럼 기차안에서 음식 못먹어?응 물만 마실 수 있어 ㅜㅜ/난 내일로 여행 가고 싶더라 하하\n",
      "일반 대화:그리고 또 어떤 학원 다녔어?나 피아노 학원 다녔어 ㅋㅋ\n",
      "일반 대화:김간호사 원장실로 잠깐 오세요.\n",
      "네. 원장님.\n",
      "김간호사 업무 시간에 뭘 그렇게 다른 일 하느라 바쁜가?\n",
      "네? 무슨 말씀이신지.\n",
      "내가 그 동안 말안하고 지나가면 안그러나 해서 참은 건데 맨날 로 개인 업무 보지 않나?\n",
      "네? 저는 개인업무를 보는게 아닌데.\n",
      "단 한번도 개인업무를 보지 않았다는 건가? 우리 로비에 있는 거 모르고 있었나?\n",
      "아니요.그건 환자들의 안전과 보안을 위해 설치되어 있다는 걸로 압니다.\n",
      "그건 당연한거고 내가 직원들 급여줘가면서 고용했는데 내가 고용한 시간에 다른 짓을 하면서 시간 떼우는 것까지 봐줘야하나?\n",
      "죄송합니다.주의하겠습니다.\n",
      "이런 식으로 하면 앞으로 더 주의 깊게 주시할 수밖에없네.\n",
      "일반 대화:사람이 약속을 했으면 지켜야지.\n",
      "무슨약속! 나는 너랑 약속을 한 적이 없어\n",
      "하 이 척추가 뒤바뀔 인간을 보겠네. 뒤지고 싶냐?\n",
      "정말이야 난 기억이 안 난다고\n",
      "내가 이거를 꺼내도 모른체 한다고\n",
      "그.그건 이러지마 난 진짜 모른다니까\n",
      "그건 당신 사정이시구요. 어디부터 뽑을까\n",
      "경찰에 신고할꺼야\n",
      "신고?살아서 나갈 수 있어야 신고도 하겠지? 새끼부터할까?\n",
      "기억나! 기억난다고\n",
      "일반 대화:비행기도 2000건 넘게 무더기 결항에아 저런 ㅠㅠ 비행기 타본지가 어어니.\n",
      "일반 대화:경주도 좋을 것 같고 화명 생태공원도 좋대헐 두 군데 다 가고 싶다\n",
      "일반 대화:직업이 군인은 맞아.그런데 직업군인은 아니야?\n",
      "일반 대화:민지씨 점심 뭐 싸왔어요?\n",
      " 네? 저 제육볶음 싸왔습니다.\n",
      "아 그래요? 잘 됐다 나랑 같이 먹어요.\n",
      "네? 저 제 것만 싸왔는데요.?\n",
      "걱정마 밥은 내가 챙겨왔어 제육볶음만 같이 먹게요.\n",
      "정말 죄송합니다. 편의점에서 통조림 사서 먹는게 어떨까요?\n",
      "장난해? 같이 먹자고 그게 좀 어려워? 나 통조림 별로 안 좋아해. 민지씨가 통조림 먹으면 되겠네.\n",
      "네? 제가 먹으려고 싸온 도시락인데요.?\n",
      "민지씨 밥먹으면서 친해지고 이러면서 대리달고 과장달고 그러는거야 알아?\n",
      "그래도 이 방법은 아닌 것 같습니다. 죄송합니다.\n",
      "일반 대화:뭐하는 새끼야\n",
      "미안해\n",
      "말로만 미안하면 다야?\n",
      "그게 아니라\n",
      "짜증나네 니 약점 다 소문낸다?\n",
      "안돼 제발\n",
      "뒷감당은 알아서 하시고\n",
      "한번만 봐주면 안될까?\n",
      "응 싫은데 내가왜?\n",
      "미안해\n",
      "일반 대화:야야 오타쿠 일루와봐\n",
      " 싫어\n",
      "싫워 아 얼른 !!\n",
      "왜에에\n",
      "왜에에에말도 어눌해요 \n",
      "따라하지마\n",
      "따롸하지뫄 오융 기분이 나빠요 ?\n",
      "아니 하지말라구\n",
      "아뉘 하지 말롸규 아니 우리보고 뭘 하지마라하라야 얼른 오기나 해\n",
      "싫어 그리고 따라하지마\n",
      "똬라하지뫄그래 오타쿠야 그렇게 가만히 앉아서 만화나 보세여에휴\n",
      "일반 대화:이게 지금 뭐하는 짓이야 감히 나한테 협박을 해?\n",
      "내가 분명 말했을텐데. 한 번만 더 주둥이 놀렸다간 너도 네 가족들도 다 죽여버릴 거라고.\n",
      "나 이 나라 대통령이야. 니까짓게 할 수 있을 것 같아?\n",
      "어차피 나한테 미래란 없어 그냥 너 죽여버리고 감옥 가지 뭐\n",
      "원하는 게 뭔가?\n",
      "이제야 말이 통하는군. 현금 10억과 내가 해외로 갈 수 있도록 전용기를 준비해. 3시간 준다.\n",
      "3시간? 그렇게 짧은 시간 안에 어떻게 준비를 하나?\n",
      "그럼 어떡할까 내 밑에 있는 부하가 네 가족들 다 데리고 있다는데. 사태 파악이 안 되나본데 네가 정녕 가족들이 한 명 씩 죽는 꼴을 봐야 네가 정신 차릴거야?\n",
      "알았네.\n",
      "허튼 수작 부리면 그냥 다 죽자는 걸로 알겠어.\n",
      "알았네. 조금만 기다려주게.\n",
      "일반 대화:야! 너네 또 뛰었지!!!\n",
      "저희 집이 뛴 거 아니라구요\n",
      "너네잖아!!!!\n",
      "저희 지금 막 외출하고 들어왔어요\n",
      "너네 진짜 죽여버린다!!!\n",
      "더 이상 어떻게 조용히 살어!!!이럴거면 아파트말고 주택에 살던지!!!!\n",
      "시!! 니네 엄마랑 니네 아들 내 눈에 띄면 다 죽여버릴거야!!!\n",
      "너 지금 뭐라고 했어!!! 니가 한 말 다 녹음해놨어!!\n",
      "니 맘대로해!!!\n",
      "그래 경찰서에서 보자!!!\n",
      "일반 대화:마음은 굴뚝 같은데 연차는 병원 갈 때 써야 함 ㅠㅠ그래... 가을은 가을이고... 우리는 일해야지 ㅠㅠ\n",
      "일반 대화:안그래도 요즘 근데 탈레반?ㅋㅋ\n",
      "일반 대화:응 한번보고 골라봐 아니면 김밥 같은거 사먹어도 괜찮지 김가네에서김가네? 아 김가네~김밥? 먹자구? 저녁밥?\n",
      "일반 대화:야 무슨 여자 다리가 그렇게 두껍냐\n",
      "뭐래 안 두껍거든\n",
      "아니 두꺼워 심각하네 무슨 코끼리 다리도 아니고 무슨 나보다 다리가 그렇게 두껍냐\n",
      "그만 좀 해 기분 나빠\n",
      "기분 나쁘면 살 좀 빼 진짜 너 심각하다\n",
      "그만해.\n",
      "엉덩이도 존나 크고 다리도 존나 두껍고 너 여자 맞냐 \n",
      "그만하라고!\n",
      "일반 대화:너 백신 맞았어?나 일차까지! 모더나 맞았어/나 일차 맞았고 2차는 내일모레 맞음 ㅋㅋ 넌,/아니 나 아직 안 맞았어! 곧 맞아/1차 맞았지\n",
      "일반 대화:ㅋㅋ 근데 나도 논산 갔다가 대전으로 갈 거 같아!논산은 진짜 할 거 없어 논산 오게?\n",
      "일반 대화:이빨을 못쓰게 뽑아버려야겠어\n",
      "왜 그러십니까\n",
      "왜긴 니놈 하는 짓거리가 거슬려서 참을 수가 있어야지\n",
      "밑도 끝도 없이 왜그러십니까 진정하세요\n",
      "진정하는건 내마음이고 니 새끼가 거슬리는 것도 내맘이지\n",
      "말씀이 너무 심하세요\n",
      "그래 니 입부터 거슬려서 이빨이라도 뽑아버리면 밥도 못먹어서 말할 힘도 없겠지 낄낄\n",
      "신고하겠습니다\n",
      "신고하기전에 강냉이 털릴텐데 괜찮겠어?\n",
      "제가 이런소리 들을 이유는 없습니다. 그만해주세요 제발\n",
      "일반 대화:ㅋㅋ 그러면 음 남자 성격?음 나는 무조건 착하고 배려 넘치는 사람이 좋아\n",
      "일반 대화:씨 이제부터 탕비실 관리는 씨가 하세요\n",
      " 네? 왜 제가 해야하는거죠? 제 업무는 그게 아닌데요\n",
      " 씨가 막내잖아요!\n",
      " 막내가 꼭 해야하나요?\n",
      " 그럼 누가해요? 저기 과장님 시킬까요?\n",
      " 아니 그런건아니지만 다같이 쓰는 탕비실을 제가 전담해야하는이유를 모르겠습니다\n",
      " 업무하는데 뭐든 이유가 있어야해요?\n",
      " 제 업무가 있는데 탕비실을 계속 신경쓰기 힘들것 같아서요\n",
      " 이제부터 탕비실도 씨 업무라니까요?\n",
      " 불공정합니다\n",
      "일반 대화:ㅋㅋ 진짜 대단하지 않았냐 나... 반쪽은 떼져가지고 달랑거리는 거 10년을 쓰고 이번에 이사 오면서 컴퓨터 싹 맞췄다ㅋㅋ 큰 맘먹고 바꾼 거 아니야 그 정도면?\n",
      "일반 대화:지금 뭐하시는 거에요?\n",
      "내가 뭘 어쨌다고 그래요?\n",
      "지금 자꾸 제 몸을 만지시자나요\n",
      "만지긴 누가 만졌다고 그래요!? 지하철에 사람이 많으니 자꾸 밀리다보니 어쩔 수 없이 그렇게 되는거지\n",
      "그 정도 수준이 아니자나요\n",
      "아 이 여자가 사람을 치한으로 만드네\n",
      "사람이 많다고 해도 자꾸 제 몸을 붙이시자나요\n",
      "사람들에게 밀리지 않으려 하다보니 힘을 줄 수 밖에 없으니 그렇게 되는거지 기가 막히네\n",
      "그런거랑은 다르잖아요 엄청 불쾌하다구요\n",
      "와 생사람 잡네 이거 미친 아냐?? 별로 이쁘지도 않은게 내가 눈이 삐어서 너같은 몸을 만지냐?\n",
      "일반 대화:로션이랑 스킨 먼저 사야겠다 ㅋㅋ응 사면서 선크림도 하나 사!\n",
      "일반 대화:뭘 그렇게 걱정하면서 징징거려?\n",
      "네? 죄송해요\n",
      "넌 내일 가만두지 않겠어\n",
      "대리님 낼 재택 아니세요?\n",
      "아주 간접 병영체험을 하게 해주마\n",
      "아 저도 이런 제가 답답해요 하.\n",
      "내가 더 답답하겠니 안하겠니?\n",
      "대리님 자료 요청 메일을 덜 보내는 방법도 있나요?\n",
      "사내 위키 잘 찾아봐\n",
      "네\n",
      "일반 대화:야.근데.이렇게 하는거 맞아.???\n",
      "맞다고 병신아!!\n",
      "야 근데 왜 자꾸 욕해.??\n",
      "왜.? 듣기 싫어??\n",
      "듣기 싫지 당연히 \n",
      "어쩌라고 병신아\n",
      "아니 진짜 기분 나쁘게 하네??\n",
      "어쩔껀데 병신아\n",
      "그만해\n",
      "싫은데 병신아?\n",
      "일반 대화:임대리는 애인 있나?\n",
      " 아뇨 없습니다\n",
      " 그래 이렇게 예쁜데\n",
      " 하하 네 감사합니다\n",
      "몸매도 예쁘고 말이야\n",
      " 죄송한데 그거 성희롱이에요\n",
      " 뭐 칭찬해줬다가 무슨 성희롱이야 뭐가 그렇게 예민해?짤리고 싶어?\n",
      "아닙니다 죄송합니다\n",
      "허 참나 딸같아서 잘해줬더니\n",
      " 죄송합니다 사장님\n",
      "일반 대화:맞아 너 그냥 일반 가위 아니었어?맞아 머리 검사 하러 오면 다들 본인 머리를 잘랐지\n",
      "일반 대화:어이 아저씨 나 만원만 주시면 안될까요?\n",
      "뭐에다 쓰려구?\n",
      "그런건 묻지말고 만원만 주세요 \n",
      "버르장머리없는 놈이! 내가 널 뭘 믿고 만원을 주냐? \n",
      "아씨 담배사게 만원만 달라고요 \n",
      "요즘 어린애들이 무서운줄모르고! \n",
      "아 좋은말할때 빨리줘라 \n",
      "야 그냥 때려버리자\n",
      "무무슨말이야 때리다니.!\n",
      "곱게 줬으면 됐잖아 쫄기는\n",
      "일반 대화:이봐!!!!김수근씨 \n",
      "네.부장님.\n",
      "이걸 지금 기획안이라고 낸거야!\n",
      "아다시 해서 올리겠습니다.\n",
      "입사한 지 얼만데 아직까지 이렇게밖에 못해!!!\n",
      "죄송합니다. 다시 하겠습니다.\n",
      "이래서 지방대 출신들은\n",
      "\n",
      "이래서 출신이 중요하다니까 어디 지방대 출신따위가.어휴\n",
      "부장님그래도 말씀이 좀.\n",
      "일반 대화:전라도는  참 음식이  맛있어 ㅋㅋ갈 곳도 좀 있고... 괜찮은 곳이야\n",
      "일반 대화:근데 상대가 보험을 못 부르게 하는거야.그게 무슨 말도 안 되는 소리야?\n",
      "일반 대화:맞아. 국가대표 선수들 정말 멋있어.나도 그렇게 생각해.\n",
      "일반 대화:야 내가 뭐 준비해왔게??? 진짜 재밌는거 가져왔는데\n",
      "왜 뭔데 뭔데??\n",
      "설사약 저번부터 민정이 재수없지 않았냐? 이번기회에 비타음료에 설사약 넣어서 힘내라고 먹으라고 하자\n",
      "헐 개 좋아 이리 줘봐 내가 넣을 테니까 너가 티 안내게 줘 먹는거 까지 다 봐야해\n",
      "민정아!! 오늘 시험이잖아 준비 많이 했어? 헐 피곤해 보이네. 이거 비타음료 11이라 샀는데 같이 먹자\n",
      "헐 고마워 와 진짜 피로 다 풀리는 느낌이야. 덕분에 오늘 시험 잘 볼 수 있겠다.\n",
      " 시험 잘 보고 끝나고 만나자!! 아프지 말고 파이팅!\n",
      "야 너 뭔짓 한거야. 내가 탈날까봐 오늘 아침에 아무것도 안 먹고 왔는데 배아프고 식은땀 나서 화장실 들락날락 거리느라 시험 제대로 보지도 못했어. 오늘 먹은거 너가 준 음료수 하나야. 의심 안 하려 해도 너가 나랑 헤어질 때 아프지말고라 해서 의문이 들었거든 너가 비타음료에 약 넣었지. 그래서 뚜껑도 따주는 척 한 거고\n",
      "너무 바로 단정 짓는거 아니야? 너 만약 나 아니었으면 어쩌려고 그랬냐 그래도 눈치는 빠르네\n",
      "왜 그런짓 했어?너 시험 범위 잘 몰라서 알려준것도 난데 너무한거 아니야?\n",
      "그니까 적당히 재수없게 굴어야지 그냥 너 업보라고 생각해. 적당이 떵떵거려. 원래 2배 넣으려다 말았네\n",
      "일반 대화:오 야야야야 저기 버스온다 쟤 잡자\n",
      "야! 왜 이래 놔 줘. 나 버스타야 해. 놔달라고\n",
      "버스 갈 때까지 놔주지마! 꽉 붙잡아!!\n",
      "야. 버스 지나갔잖아.아무리 친구 사이여도 이런 장난은 너무 하지 않냐? 더군다나 내가 오늘 학원 시험 있다고 했잖아. 그거 기준점보다 떨어지면 학원 퇴출이란 말이야. 우리 엄마가 얼마나 힘들게 등록해놓으신 학원인데. 어떻게 책임질거야!\n",
      "뭘 책임져. 야야 어쩌피 너 성적도 별로 안 나오잖아. 좋은 학원 아니라는거야 참된 우정을 택한 당신 멋져용 어쩌피 이제 놀 겸 피시방이나가자\n",
      "장난하려 하지 마. 나 무단결석이라 이제 퇴출 확정이야. 지금 우리 고2야 그런 중요한 시기에 어떻게 학원을 옮겨서 수업을 들어. 너가 내 인생 다 망쳤어. 너 때문에 대학 못 가면 어쩌려그래.\n",
      "예 너무 진지하게 받네 야 너 그깟 학원 퇴출 당했다고 인생 망하는거 아니야. 이미 너가 예전부터 차근차근 너 인생 망하는 길로 진입했잖아.이제 핑계 될 거 없어서 이런걸로? 넌 글러먹었다.\n",
      "너네가 나 버스 못타게 잡아놓고 왜 이렇게 당당해? 잡지를 말았어야지\n",
      "버스비 줄테니까 가. 진짜 짜증나게 하네. 야 공부도 못 하면서 유세 떨려 하지 마. 뭔 자꾸 인생을 망친다 타령이야. 그렇게 붙잡는 게 기분 나빴냐? 근데 어째 난 사과할 마음 하나도 없는데. 쥐 똥만한 성적으로 공부 되게 열심히 하는 척 하네. 야 니 본분을 알고 살아. 공부도 못하고 상황에 따라 머리도 못 굴리는 애가.\n",
      "너가 잘못해놓고 너무하네. 내가 이런 말 까지 들어야 해.?\n",
      "일반 대화:야 1반 찐따\n",
      "왜 불러.\n",
      "니네 누나는 너랑 다르게 찐따는 아니더라 반대던데?\n",
      "어.어.\n",
      "유전자 몰빵이 그런건가보지?\n",
      "누나 이야기는 왜하는거야\n",
      "아니 니네 누나가 내스탈이라서 연락처좀 건내줘\n",
      "안돼.우리누나는 괴롭히지마\n",
      "누가 괴롭힌데 병신아 장난아니니까연락처 건네주라고\n",
      "시.싫어\n",
      "그래? 그럼 니입에서 좋다는 소리가 나올때까지 디지게 맞든가\n",
      "아니면 매형소리 나올때까지 쳐맞을까?\n",
      "일반 대화:지금 봤는데 지위픽도 파네 ㅋㅋ다행이다 하하/잘됐다 하하 사는김에 강아지 장난감도 같이 사\n",
      "일반 대화:확실하나 주사 싫어.주사도 너 싫어해 ^^\n",
      "일반 대화:유 대리. 지금 출근한 건가?\n",
      "네 차장님 조금 전 출근했습니다.\n",
      "지금 시간이 몇 시인데 지금 출근하는 거야? 정신을 대체 어디다 두고 다니는 거야?\n",
      "죄송합니다 앞으로 조금 더 빨리 나오도록 하겠습니다.\n",
      "유 대리 사원 때도 근태 불량하더니 승진하고도 고치지를 못하네. 지금 팀 바쁜 거 몰라?\n",
      "알고 있습니다.\n",
      "알고 있으면 원래 출근시간보다 더 빨리 나와서 도울 생각을 해야지 오히려 시간 맞춰 나오면 어쩌자는 거야?\n",
      "정말 죄송합니다.\n",
      "신입사원도 아니고 이런 걸 다 얘기해 줘야 하나 싶다 정말.\n",
      "제가 앞으로 더 신경 쓰겠습니다.\n",
      "일반 대화:신기하네 카페인이 안 받는 건가맞아/그렁 거 같음/그래서 맨날 스무디 먹음\n",
      "일반 대화:너 물건 환불하고 반품해본 적 있어?응응 몇 번 해봤어!\n",
      "일반 대화:맞아 인공지능 발달 멈춰 ㅜ지니야 발달 멈춰~\n",
      "일반 대화:너는 결혼 안해?\n",
      "글쎄 나는 결혼 할 생각이 없는데\n",
      "못하는게 아니고 ?\n",
      "뭐?\n",
      "아니 직장도 그냥 그렇고 남자도 없고 너 그러다 노처녀 소리들어\n",
      "니가 할말은 아닌거같은데\n",
      "왜? 나는 지금 신혼생활 잘 지내고있는데? 너랑 다르지\n",
      "하 .\n",
      "빨리 좋은남자 만나서 결혼해 여자는 나이 많으면 아무도 안 데려간다 여자로 태어났으면 결혼도 하고 애도 낳고 여자로서 할 수 있는건 늦기전에 해봐야지 너 너무 늦으면 애도 못 갖는 몸 된다\n",
      "너 말이면 다야?\n"
     ]
    }
   ],
   "source": [
    "# 파인 튜닝 이후 추론\n",
    "# 모델을 eval 모델로 전환\n",
    "model.eval()\n",
    "\n",
    "# 모델 예측을 담을 preds라는 빈 컨테이너 리스트 생성\n",
    "preds = []\n",
    "\n",
    "# 이하 코드의 설명은 문제 45 코드 참조\n",
    "with torch.no_grad():\n",
    "  for sentence in X_test_list:\n",
    "    inputs = tokenizer.encode(sentence, return_tensors=\"pt\",padding=True, truncation=True)\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    logits = outputs.logits\n",
    "    pred = logits.argmax(-1).item()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    preds.append(logits.argmax(-1).item())\n",
    "    print(f\"{dic[pred]}:{sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "D3N2jh0ecAAi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:48.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185/2313815014.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(preds)\n"
     ]
    }
   ],
   "source": [
    "ans = torch.tensor(y_test_list)\n",
    "preds = torch.tensor(preds)\n",
    "print(f\"Accuracy:{100 * sum(ans.detach().clone()==preds)/len(ans.detach().clone())}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
